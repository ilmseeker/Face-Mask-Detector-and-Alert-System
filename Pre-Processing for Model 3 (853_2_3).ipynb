{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing of modified dataset (for Model No. - 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import cv2\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols = 224, 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '2']\n"
     ]
    }
   ],
   "source": [
    "Dataset = 'C:/XPS/MSc Data/Completed Projects/Research Project/Datasets/853_2_3/'\n",
    "# Dataset = '853_2_3'\n",
    "Data_Dir = os.listdir(Dataset)\n",
    "print(Data_Dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_853_2_3 = []\n",
    "\n",
    "for category in Data_Dir:\n",
    "  folder_path = os.path.join(Dataset, category)\n",
    "  class_num = Data_Dir.index(category)\n",
    "  \n",
    "  for image in os.listdir(folder_path):\n",
    "    new_image_path = os.path.join(folder_path, image)\n",
    "    image = cv2.imread(new_image_path)\n",
    "    \n",
    "    try:\n",
    "      gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "      resized_image = cv2.resize(gray_image, (img_rows, img_cols))\n",
    "      data_853_2_3.append([resized_image, class_num])\n",
    "    except Exception as e:\n",
    "      print(\"Exception:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10696"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_853_2_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 38,  38,  38, ...,  41,  60,  69],\n",
       "        [ 37,  37,  37, ...,  38,  56,  64],\n",
       "        [ 37,  36,  35, ...,  35,  50,  57],\n",
       "        ...,\n",
       "        [ 18,  18,  19, ..., 139, 135, 134],\n",
       "        [ 18,  18,  18, ..., 139, 136, 135],\n",
       "        [ 19,  19,  18, ..., 139, 137, 136]], dtype=uint8),\n",
       " 0]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_853_2_3[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(data_853_2_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data,labels in data_853_2_3:\n",
    "    X.append(data)\n",
    "    y.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X is a :  <class 'list'> \n",
      "\n",
      "y is a :  <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(\"X is a : \", type(X), '\\n')\n",
    "print(\"y is a : \", type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X).reshape(-1, img_rows, img_cols, 1)\n",
    "X = X/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(y)\n",
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the files\n",
    "pickle_out = open(\"X_853_2_3.pickle\", \"wb\")\n",
    "pickle.dump(X, pickle_out, protocol=4)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open(\"y_853_2_3.pickle\", \"wb\")\n",
    "pickle.dump(y, pickle_out, protocol=4)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X :  (10696, 224, 224, 1)  &  Type : <class 'numpy.ndarray'> \n",
      "\n",
      "Shape of y :  (10696, 3)  &  Type : <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X : \", X.shape, ' & ', \"Type :\", type(X), '\\n')\n",
    "print(\"Shape of y : \", y.shape, ' & ', \"Type :\", type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X :  (10696, 224, 224, 1)  &  Type : <class 'numpy.ndarray'> \n",
      "\n",
      "Shape of y :  (10696, 3)  &  Type : <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# For Loading the dumps\n",
    "pickle_in = open(\"C:/XPS/MSc Data/Completed Projects/Research Project/Datasets/X_853_2_3.pickle\", \"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"C:/XPS/MSc Data/Completed Projects/Research Project/Datasets/y_853_2_3.pickle\", \"rb\")\n",
    "y = pickle.load(pickle_in)\n",
    "\n",
    "print(\"Shape of X : \", X.shape, ' & ', \"Type :\", type(X), '\\n')\n",
    "print(\"Shape of y : \", y.shape, ' & ', \"Type :\", type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Images : 10696 and Length of Labels : 10696 \n",
      "\n",
      "len(X_train) : 7486, len(X_val) : 1070, len(X_test) : 2140 \n",
      "\n",
      "len(y_train) : 7486, len(y_val) : 1070, len(y_test) : 2140\n"
     ]
    }
   ],
   "source": [
    "# Model Ratio - Train:Val:Test = 70:10:20\n",
    "\n",
    "# 80:20 Train:Test\n",
    "(X_train, X_test, y_train, y_test) = train_test_split(X, \n",
    "                                                      y, \n",
    "                                                      train_size=0.80, \n",
    "                                                      random_state=42)\n",
    "\n",
    "# Train:Val. We need 70% as training set. So, 70/80 = 0.875 and Val = 1-0.875=0.125 \n",
    "(X_train, X_val, y_train, y_val) = train_test_split(X_train, \n",
    "                                                    y_train, \n",
    "                                                    train_size=0.875, \n",
    "                                                    random_state=42)\n",
    "\n",
    "print(\"Length of Images : {} and Length of Labels : {} \\n\\nlen(X_train) : {}, len(X_val) : {}, len(X_test) : \\\n",
    "{} \\n\\nlen(y_train) : {}, len(y_val) : {}, len(y_test) : {}\".format(len(X), \n",
    "                                                                    len(y),\n",
    "                                                                    len(X_train), \n",
    "                                                                    len(X_val), \n",
    "                                                                    len(X_test), \n",
    "                                                                    len(y_train), \n",
    "                                                                    len(y_val), \n",
    "                                                                    len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4235 Images in y_train with mask : Label 0\n",
      "There are 1868 Images in y_train without mask : Label 1\n",
      "There are 1383 Images in y_train without proper mask : Label 2 \n",
      "\n",
      "There are 0639 Images in y_val with mask : Label 0\n",
      "There are 0232 Images in y_val without mask : Label 1\n",
      "There are 0199 Images in y_val without proper mask : Label 2 \n",
      "\n",
      "There are 1187 Images in y_test with mask : Label 0\n",
      "There are 0535 Images in y_test without mask : Label 1\n",
      "There are 0418 Images in y_test without proper mask : Label 2\n"
     ]
    }
   ],
   "source": [
    "zero_train = []\n",
    "one_train = []\n",
    "two_train = []\n",
    "zero_val = []\n",
    "one_val = []\n",
    "two_val = []\n",
    "zero_test = []\n",
    "one_test = []\n",
    "two_test = []\n",
    "\n",
    "# Works when the data is in array format\n",
    "for i in y_train[:,0] == 1.: # Returns Boolean Value\n",
    "  zero_train.append(i)\n",
    "\n",
    "for j in y_train[:,1] == 1.:\n",
    "  one_train.append(j)\n",
    "\n",
    "for k in y_train[:,2] == 1.:\n",
    "  two_train.append(k)\n",
    "\n",
    "for l in y_val[:,0] == 1.:\n",
    "  zero_val.append(l)\n",
    "\n",
    "for m in y_val[:,1] == 1.:\n",
    "  one_val.append(m)\n",
    "\n",
    "for n in y_val[:,2] == 1.:\n",
    "  two_val.append(n)\n",
    "\n",
    "for o in y_test[:,0] == 1.:\n",
    "  zero_test.append(o)\n",
    "\n",
    "for p in y_test[:,1] == 1.:\n",
    "  one_test.append(p)\n",
    "\n",
    "for q in y_test[:,2] == 1.:\n",
    "  two_test.append(q)\n",
    "\n",
    "print(\"There are \"'{:04d}'.format(sum(zero_train)) + \" Images in y_train with mask : Label 0\") # For counting sum of Boolean Values\n",
    "print(\"There are \"'{:04d}'.format(sum(one_train)) + \" Images in y_train without mask : Label 1\") \n",
    "print(\"There are \"'{:04d}'.format(sum(two_train)) + \" Images in y_train without proper mask : Label 2\", '\\n')\n",
    "\n",
    "print(\"There are \"'{:04d}'.format(sum(zero_val)) + \" Images in y_val with mask : Label 0\") # For counting sum of Boolean Values\n",
    "print(\"There are \"'{:04d}'.format(sum(one_val)) + \" Images in y_val without mask : Label 1\") \n",
    "print(\"There are \"'{:04d}'.format(sum(two_val)) + \" Images in y_val without proper mask : Label 2\", '\\n')\n",
    "\n",
    "print(\"There are \"'{:04d}'.format(sum(zero_test)) + \" Images in y_test with mask : Label 0\") # For counting sum of Boolean Values\n",
    "print(\"There are \"'{:04d}'.format(sum(one_test)) + \" Images in y_test without mask : Label 1\") \n",
    "print(\"There are \"'{:04d}'.format(sum(two_test)) + \" Images in y_test without proper mask : Label 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving files for future use\n",
    "\n",
    "pickle_out = open(\"X_train_X_853_2_3.pickle\", \"wb\")\n",
    "pickle.dump(X_train, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"X_val_X_853_2_3.pickle\", \"wb\")\n",
    "pickle.dump(X_val, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"X_test_X_853_2_3.pickle\", \"wb\")\n",
    "pickle.dump(X_test, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"y_train_y_853_2_3.pickle\", \"wb\")\n",
    "pickle.dump(y_train, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"y_val_y_853_2_3.pickle\", \"wb\")\n",
    "pickle.dump(y_val, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"y_test_y_853_2_3.pickle\", \"wb\")\n",
    "pickle.dump(y_test, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We will use these data subsets in Google Colab notebook for compiling our models. The filesize of 'X' was exceeding 4GB and Google Colab was unable to handle the operation of such a large file. So, I have pre-processed the dataset at local machine. I will use these final dumps in our main Google Colab notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
